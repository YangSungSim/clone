#네이버에서 나스닥, 니케이, 다우존스 해외 지수를 텍스트 파일에 옮겨 두는 코드
from urllib.request import urlopen
import bs4
import webbrower
import datetime as dt

#basic setting

def date_format(d):
    d = str(d)
    yyyy = int(d.split('.')[0])
    mm = d.split('.')[1]
    dd = d.split('.')[2]

    rule = '{}/{}/{}'.format(mm,dd,yyyy)
    return rule

index_cd1 = ['DJI@DJI','NAS@IXIC']
index_cd2 = ['NII@NI225']

def dow_nas(i):
    naver_index = 'https://finance.naver.com/world/sise.nhn?symbol=' + i

    source = urlopen(naver_index).read()
    source = bs4.BeautifulSoup(source, 'lxml')
    dates = source.find_all('td', class_='tb_td')

    Siga = source.find_all('td', class_='tb_td4')
    Goga = source.find_all('td', class_='tb_td5')
    Jeoga = source.find_all('td', class_='tb_td6')
    Jongga = source.find_all('td', class_='tb_td2')

    a = str(dates[0]).replace('<td class="tb_td">', "")
    a = a.replace('</td>', "")
    a = date_format(a)
    b = str(Siga[0]).replace('<td class="tb_td4"><span>', "")
    b = b.replace('</span></td>', "")
    b = b.replace(',','')
    c = str(Goga[0]).replace('<td class="tb_td5"><span>', "")
    c = c.replace('</span></td>', "")
    c = c.replace(',', '')
    d = str(Jeoga[0]).replace('<td class="tb_td6"><span>', "")
    d = d.replace('</span></td>', "")
    d = d.replace(',', '')
    e = str(Jongga[0]).replace('<td class="tb_td2"><span>', "")
    e = e.replace('</span></td>', "")
    e = e.replace(',', '')

    return [a,b,c,d,e]
nas_dow=[]
for i in index_cd1:
    k = dow_nas(i)
    nas_dow.append(k)

#나스닥 다우존스 텍스트 기입
dowjones = open('//Fos_00/!동기화/dowjones.txt','a',encoding='utf-8')
data = '\n'+nas_dow[0][0]+',1630,'+nas_dow[0][1]+' ,'+nas_dow[0][2]+' ,'+nas_dow[0][3]+' ,'+nas_dow[0][4]+' ,0,0'
dowjones.write(data)
dowjones.close()

nasdaq1 = open('//Fos_00/!동기화/1-comp-2.txt','a',encoding='utf-8')
nasdaq2 = open('//Fos_00/!동기화/COMP_H.txt','a',encoding='utf-8')
nasdaq3 = open('//Fos_00/!동기화/COMP_휴일.txt','a',encoding='utf-8')
data ='\n'+ nas_dow[1][0]+',1630,'+nas_dow[1][1]+' ,'+nas_dow[1][2]+' ,'+nas_dow[1][3]+' ,'+nas_dow[1][4]+' ,0,0'
nasdaq1.write(data)
nasdaq2.write(data)
nasdaq3.write(data)
nasdaq1.close()
nasdaq2.close()
nasdaq3.close()

def Nikkei():
    naver_index = 'https://finance.naver.com/world/sise.nhn?symbol=' + index_cd2[0]

    source = urlopen(naver_index).read()
    source = bs4.BeautifulSoup(source, 'lxml')
    dates = source.find_all('td', class_='tb_td')

    Siga = source.find_all('td', class_='tb_td4')
    Goga = source.find_all('td', class_='tb_td5')
    Jeoga = source.find_all('td', class_='tb_td6')
    Jongga = source.find_all('td', class_='tb_td2')

    sise = []

    a = str(dates[0]).replace('<td class="tb_td">', "")
    a = a.replace('</td>', "")
    a = date_format(a)
    aa = str(dates[1]).replace('<td class="tb_td">', "")
    aa = aa.replace('</td>', "")
    aa = date_format(aa)
    b = str(Siga[0]).replace('<td class="tb_td4"><span>', "")
    b = b.replace('</span></td>', "")
    b = b.replace(',', '')
    c = str(Goga[0]).replace('<td class="tb_td5"><span>', "")
    c = c.replace('</span></td>', "")
    c = c.replace(',', '')
    d = str(Jeoga[0]).replace('<td class="tb_td6"><span>', "")
    d = d.replace('</span></td>', "")
    d = d.replace(',', '')
    e = str(Jongga[0]).replace('<td class="tb_td2"><span>', "")
    e = e.replace('</span></td>', "")
    e = e.replace(',', '')

    sise.append([a,b,c,d,e])
    sise.append([aa,b,c,d,e])

    return sise

#니케이 데이터 입력
nikkei1 = open('//Fos_00/!동기화/Nikkei.txt','a',encoding='utf-8')
nikkei2 = open('//Fos_00/!동기화/Nikkei2.txt','a',encoding='utf-8')
k = Nikkei()
data1 = '\n'+k[0][0]+',1630,'+k[0][1]+' ,'+k[0][2]+' ,'+k[0][3]+' ,'+k[0][4]+' ,0,0'
data2 = '\n'+k[1][0]+',1630,'+k[1][1]+' ,'+k[1][2]+' ,'+k[1][3]+' ,'+k[1][4]+' ,0,0'
nikkei1.write(data1)
nikkei2.write(data2)
nikkei1.close()
nikkei2.close()


#put 과 call 시세를 받아적기위한 웹페이지 열기
webbrowser.open_new("http://marketdata.krx.co.kr/mdi#document=13050302")

def put_call():
    krx_index = 'https://finance.naver.com/world/sise.nhn?symbol=DJI@DJI'
    source = urlopen(krx_index).read()
    source = bs4.BeautifulSoup(source, 'lxml')

    dates = source.find_all('td', class_='tb_td')

    a = str(dates[0]).replace('<td class="tb_td">', "")
    a = a.replace('</td>', "")
    a = date_format(a)

    return a

k = open('//Fos_00/!동기화/call_kk.txt','a',encoding='utf-8')
r = open('//Fos_00/!동기화/put_kk.txt','a',encoding='utf-8')
data1 = '\n'+put_call()+',1630,'
k.write(data1)
r.write(data1)

k.close()
r.close()
